{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from function_library import *\n",
    "from function_library2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out all the people related in Edison project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load people list from pickle\n",
    "# maybe should save body and title into pickle as well?\n",
    "l_from = fromPickle(\"from_list\")\n",
    "l_to   = fromPickle(\"to_list\")\n",
    "l_cc   = fromPickle(\"cc_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df with body\n",
    "df = pd.read_csv('output4.csv')\n",
    "df['Sent'] = pd.to_datetime(df['Sent'])\n",
    "df = df[df['Sent'] > datetime( 2012, 1, 1, 0, 0, 0)]\n",
    "body = df['Body'].values\n",
    "subject = df['Subject'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if edison appear in the subject or the body, save the index\n",
    "# GE: you can probably get faster execution using the pd.apply function\n",
    "edison = 'edison'\n",
    "idx_list = []\n",
    "for idx in range(len(body)):\n",
    "    if edison in body[idx].lower() or edison in subject[idx].lower():\n",
    "        idx_list.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the senders using the index list \n",
    "from_list = standardize_triplet(np.array(l_from)[idx_list].tolist())\n",
    "name_list = set(from_list)\n",
    "\n",
    "# find all the recipients using the index list \n",
    "to_list = standardize_triplet(np.array(l_to)[idx_list].tolist())\n",
    "for names in to_list:\n",
    "    # GE: I do not follow the logic\n",
    "    name_list |= set(names)\n",
    "cc_list = standardize_triplet(np.array(l_cc)[idx_list].tolist())\n",
    "for names in cc_list:\n",
    "    name_list |= set(names)\n",
    "\n",
    "# convert to list and sort, in order to save to a txt\n",
    "name_list = list(name_list)\n",
    "name_list.sort()\n",
    "#name_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a text file\n",
    "# GE: person[i] is the triplet (first name, last name, email)\n",
    "# GE: person[0] is ('','',''). Is this always true? Or does it depend on the data? \n",
    "# GE:    if not always true, the code below will not always work.\n",
    "with open('edison_people_list.txt', 'w') as filehandle:\n",
    "    for person in name_list[1:]:\n",
    "        filehandle.write('{} {}: {}\\n'.format(person[0], person[1], person[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick out all the related emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick out all the related emails and save into another csv\n",
    "# GE: make sure you explain to our team what criteria you used to extract Edison-related emails\n",
    "\n",
    "df_edison = df.iloc[idx_list]\n",
    "\n",
    "# GE: Why are there 'Unnamed: 0' in df_edison? I thought we had cleaned up the emails\n",
    "# GE: to make sure these columns do not appear, you must use pd.read_csv and/or df.to_csv\n",
    "# GE: with an additional argument: \n",
    "del df_edison['Unnamed: 0']\n",
    "del df_edison['Unnamed: 0.1']\n",
    "\n",
    "df_edison.to_csv('edison_emails.csv')\n",
    "#df_edison.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of emails related \n",
    "len(idx_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find abnormal action by looking at sending time\n",
    "* **All emails are used**  \n",
    "* **The sending time is divided into 4 ranges. The idea is to focus on the emails sent outside regular work hours**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the sending time in 4 time ranges\n",
    "l_hour = fromPickle(\"hour_list\")\n",
    "l_hour_partition = []\n",
    "for hour in l_hour:\n",
    "    if hour>=4 and hour<=7:\n",
    "        l_hour_partition.append(1)\n",
    "    elif hour>=8 and hour<=16:\n",
    "        l_hour_partition.append(2)\n",
    "    elif hour>=17 and hour<=20:\n",
    "        l_hour_partition.append(3)\n",
    "    else:\n",
    "        l_hour_partition.append(4)\n",
    "toPickle(l_hour_partition, 'hour_partition')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_year = fromPickle(\"year_list\")\n",
    "l_week = fromPickle(\"week_list\")\n",
    "l_month = fromPickle(\"month_list\")\n",
    "l_dayofyear = fromPickle(\"dayofyear_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix, #year by #day by #time_range+1\n",
    "# GE: what do the dimensionsof hour_range_by_day represent?\n",
    "hour_range_by_day = np.zeros((6,366,5))\n",
    "for i in range(len(l_hour_partition)):\n",
    "    ix = l_year[i]-2012\n",
    "    iy = l_dayofyear[i]-1\n",
    "    iz = l_hour_partition[i]-1\n",
    "    # GE: explain the next two lines.\n",
    "    hour_range_by_day[ix,iy,iz] += 1    \n",
    "    hour_range_by_day[ix,iy,4] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time_range_labels = ['before work (4am-8am)','work time (8am-5pm)', 'after work (5pm-9pm)', 'night time (9pm-4am)']\n",
    "\n",
    "plt.figure(figsize = (15,3))\n",
    "for i in range(4):\n",
    "    #GE: why are the first two indices of hour_range_by_dan?\n",
    "    temp = np.reshape(hour_range_by_day[:,:,i], -1)\n",
    "    plt.plot(temp, label = time_range_labels[i])\n",
    "plt.legend()\n",
    "plt.title('# of emails in 4 time partitions')\n",
    "plt.show()\n",
    "\n",
    "hour_partition_sum = np.reshape(hour_range_by_day[:,:,4], -1)\n",
    "plt.figure(figsize = (15,3))\n",
    "for i in range(4):\n",
    "    temp = np.reshape(hour_range_by_day[:,:,i], -1)\n",
    "    plt.plot(temp/hour_partition_sum, label = time_range_labels[i])\n",
    "plt.legend()\n",
    "plt.title('fraction of emails in 4 time partitions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using day as the base unit may be too dense. 12000 emails in 2000 days, six per day in average.**  \n",
    "**So I try to use a weekly scale below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix, #year by #week by #time_range+1\n",
    "hour_range_by_week = np.zeros((6,52,5))\n",
    "for i in range(len(l_hour_partition)):\n",
    "    ix = l_year[i]-2012\n",
    "    iy = l_week[i]-1\n",
    "    iz = l_hour_partition[i]-1\n",
    "    if iy == 52:\n",
    "        continue\n",
    "    hour_range_by_week[ix,iy,iz] += 1   # GE: iz = 0,1,2,3\n",
    "    hour_range_by_week[ix,iy,4] += 1 # GE: what is this for?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,3))\n",
    "for i in range(4):\n",
    "    temp = np.reshape(hour_range_by_week[:,:,i], -1)\n",
    "    plt.plot(temp, label = time_range_labels[i])\n",
    "plt.legend()\n",
    "plt.title('# of emails in 4 time partitions')\n",
    "plt.show()\n",
    "\n",
    "hour_partition_sum = np.reshape(hour_range_by_week[:,:,4], -1)\n",
    "plt.figure(figsize = (15,3))\n",
    "for i in range(4):\n",
    "    temp = np.reshape(hour_range_by_week[:,:,i], -1)\n",
    "    plt.plot(temp/hour_partition_sum, label = time_range_labels[i])\n",
    "plt.legend()\n",
    "plt.title('fraction of emails in 4 time partitions')\n",
    "plt1 = plt\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only apply on Edison emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('edison_emails.csv')\n",
    "df['Sent'] = pd.to_datetime(df['Sent'])\n",
    "del df['Unnamed: 0']\n",
    "df['year']    = df['Sent'].dt.year\n",
    "df['month']   = df['Sent'].dt.month\n",
    "df['week']    = df['Sent'].dt.week\n",
    "df['weekday'] = df['Sent'].dt.weekday\n",
    "df['day'] = df['Sent'].dt.day\n",
    "df['dayofyear'] = df['Sent'].dt.dayofyear\n",
    "df['hour']    = df['Sent'].dt.hour\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the sending time in 4 time ranges\n",
    "\n",
    "# GE: this is 100% identical to the cells above for the entire set of emails?\n",
    "\n",
    "l_hour = df['hour'].tolist()\n",
    "l_hour_partition = []\n",
    "for hour in l_hour:\n",
    "    if hour>=4 and hour<=7:\n",
    "        l_hour_partition.append(1)\n",
    "    elif hour>=8 and hour<=16:\n",
    "        l_hour_partition.append(2)\n",
    "    elif hour>=17 and hour<=20:\n",
    "        l_hour_partition.append(3)\n",
    "    else:\n",
    "        l_hour_partition.append(4)\n",
    "toPickle(l_hour_partition, 'hour_partition')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_year = df['year'].tolist()\n",
    "l_week = df['week'].tolist()\n",
    "l_month = df['month'].tolist()\n",
    "l_dayofyear = df['dayofyear'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix, #year by #week by #time_range+1\n",
    "hour_range_by_week = np.zeros((6,52,5))\n",
    "for i in range(len(l_hour_partition)):\n",
    "    ix = l_year[i]-2012\n",
    "    iy = l_week[i]-1\n",
    "    iz = l_hour_partition[i]-1\n",
    "    if iy == 52:\n",
    "        continue\n",
    "    hour_range_by_week[ix,iy,iz] += 1    \n",
    "    hour_range_by_week[ix,iy,4] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,3))\n",
    "for i in range(4):\n",
    "    temp = np.reshape(hour_range_by_week[:,:,i], -1)\n",
    "    plt.plot(temp, label = time_range_labels[i])\n",
    "plt.legend()\n",
    "plt.title('# of emails in 4 time partitions')\n",
    "plt.show()\n",
    "\n",
    "hour_partition_sum = np.reshape(hour_range_by_week[:,:,4], -1)\n",
    "plt.figure(figsize = (15,3))\n",
    "for i in range(4):\n",
    "    temp = np.reshape(hour_range_by_week[:,:,i], -1)\n",
    "    plt.plot(temp/hour_partition_sum, label = time_range_labels[i])\n",
    "plt.legend()\n",
    "plt.title('fraction of emails in 4 time partitions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring style analysis using POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_clean_output.csv')\n",
    "df['Sent'] = pd.to_datetime(df['Sent'])\n",
    "df = df[df['Sent'] > datetime( 2012, 1, 1, 0, 0, 0)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GE: this is per email? Do you also analyze the subjects, or not? \n",
    "df_pos = pd.read_csv('pos_counts.csv')  # GE: for all emails\n",
    "del df_pos['Unnamed: 0']\n",
    "df_pos_edison = df_pos.iloc[idx_list]   # GE: only for Edison emails\n",
    "unique_pos_tags = df_pos_edison.columns # GE: what do you mean by unique_pos_tags?\n",
    "df_pos_edison.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "mat_pos_edison = df_pos_edison.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_top = 50\n",
    "plt.figure(figsize = (18,3))\n",
    "for i in range(len(idx_list)):\n",
    "    row = mat_pos_edison[i,:]\n",
    "    if row.sum() > 5000:\n",
    "        continue\n",
    "    plt.bar(np.arange(0,len(row),1),row, alpha = 0.5, label = 'email {}'.format(i) )\n",
    "    if i == nb_top:\n",
    "        break\n",
    "plt.xticks(np.arange(0,len(row),1), unique_pos_tags)\n",
    "#plt.legend()\n",
    "plt.title('Showing the POS distribution of first {} emails in Edison project'.format(nb_top))\n",
    "plt.show()\n",
    "\n",
    "# GE: YOu could create a table of what the different POS labels mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some emails are extremely long. I put them in a list for further use\n",
    "long_email_idx_list = []\n",
    "for i in range(len(idx_list)):\n",
    "    row = mat_pos_edison[i,:]\n",
    "    if row.sum() > 5000:  #GE: emails > 5000 characters long\n",
    "        long_email_idx_list.append(i)\n",
    "long_email_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get propotion of pos in each email\n",
    "m,n = mat_pos_edison.shape\n",
    "mat_pos_edison_normed = np.zeros_like(mat_pos_edison)\n",
    "for i in range(m):\n",
    "    if mat_pos_edison[i,:].sum() != 0:\n",
    "        mat_pos_edison_normed[i,:] = mat_pos_edison[i,:]/mat_pos_edison[i,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_edison_normed = pd.DataFrame(mat_pos_edison_normed, columns=unique_pos_tags)\n",
    "df_pos_edison_normed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_top = 10\n",
    "plt.figure(figsize = (18,3))\n",
    "for i in range(len(idx_list)):\n",
    "    row = mat_pos_edison_normed[i,:]\n",
    "    if i in long_email_idx_list:\n",
    "        continue\n",
    "    plt.bar(np.arange(0,len(row),1),row, alpha = 0.5, label = 'email {}'.format(i) )\n",
    "    if i == nb_top:\n",
    "        break\n",
    "plt.xticks(np.arange(0,len(row),1), unique_pos_tags)\n",
    "plt.legend()\n",
    "plt.title('Showing the POS proportion of first {} emails in Edison project'.format(nb_top))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most different email by comparing the distance of POS vector for each email and the average vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_dists = []\n",
    "proportion_mean = mat_pos_edison_normed.mean(axis=0)\n",
    "for i in range(len(idx_list)):\n",
    "#     if i in long_email_idx_list:\n",
    "#         proportion_dists.append(-1)\n",
    "#         continue\n",
    "    row = mat_pos_edison_normed[i,:]\n",
    "    proportion_dists.append(np.linalg.norm(proportion_mean-row))\n",
    "proportion_dists = np.array(proportion_dists)\n",
    "proportion_dists.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_dists.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[115]['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

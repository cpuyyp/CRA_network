{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joey's version in root CRA folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Joey's-version-in-root-CRA-folder\" data-toc-modified-id=\"Joey's-version-in-root-CRA-folder-0.0.1\"><span class=\"toc-item-num\">0.0.1&nbsp;&nbsp;</span>Joey's version in root CRA folder</a></span></li></ul></li></ul></li><li><span><a href=\"#Transform-text-files-to-emails\" data-toc-modified-id=\"Transform-text-files-to-emails-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Transform text files to emails</a></span></li><li><span><a href=\"#Make-dicts-and-def-functions\" data-toc-modified-id=\"Make-dicts-and-def-functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Make dicts and def functions</a></span></li><li><span><a href=\"#Usage\" data-toc-modified-id=\"Usage-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Usage</a></span></li><li><span><a href=\"#non-function-code-below\" data-toc-modified-id=\"non-function-code-below-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>non function code below</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform text files to emails\n",
    "* File names contain: \n",
    "    * an immutable email id\n",
    "    * the file name that contains the email\n",
    "    * the line number that locates the email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dicts and def functions\n",
    "\n",
    "**All cells below are necessary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass, field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex in headerReLib must have one and ONLY one pair of parenthese.\n",
    "headerReLib = {}  # dict{regex: str}\n",
    "headerReLib[re.compile(r'^From\\:\\s?(.*)')] = 'From'\n",
    "headerReLib[re.compile(r'^Sent\\:\\s?(.*)')] = 'Sent'\n",
    "headerReLib[re.compile(r'^Date\\:\\s?(.*)')] = 'Sent'\n",
    "headerReLib[re.compile(r'^To\\:\\s?(.*)')] = 'To'\n",
    "headerReLib[re.compile(r'^C[Cc]\\:\\s?(.*)')] = 'CC'\n",
    "headerReLib[re.compile(r'^B[Cc][Cc]\\:\\s?(.*)')] = 'BCC'\n",
    "headerReLib[re.compile(r'^Subject\\:\\s?(.*)')] = 'Subject' \n",
    "headerReLib[re.compile(r'^Attachments\\:\\s?(.*)')] = 'Attachments'  # Attachment: is not reliable in 9-1\n",
    "headerReLib[re.compile(r'Importance\\:\\s?(.*)')] = 'Importance'\n",
    "headerReLib[re.compile(r'Priority\\:\\s?(.*)')] = 'Importance'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanReLib = {} # dict{regex: str}\n",
    "cleanReLib[re.compile(r'^Page\\s\\d+$')] = 'Page number'\n",
    "cleanReLib[re.compile(r'^Page\\s\\d+\\sof\\s\\d+$')] = 'Page number'\n",
    "cleanReLib[re.compile(r'^\\d{,3}\\-\\d{,3}$')] = 'Page number and file number'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "typoLib = {} # dict{str: str}\n",
    "typoLib['ARachments'] = 'Attachments'\n",
    "typoLib['AFachments'] = 'Attachments'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveEmail(email, sv_arg):\n",
    "    # save in specific order\n",
<<<<<<< HEAD
    "    saving_order = ['From', 'Sent', 'To', 'CC', 'Bcc', 'Subject', 'Attachments', 'Importance', 'Body', 'isThread', 'isAutoMessage', 'hasAllCapLine', 'hasBadDate']\n",
    "    bool_headers = ['isThread', 'isAutoMessage', 'hasAllCapLine', 'hasBadDate']\n",
    "    with open(sv_arg.outputpath + '/'+str(sv_arg.email_count)+'-fn_'+sv_arg.infile.split('.')[0]+'-ln_'+str(sv_arg.line_no)+'.txt', 'w+', encoding = 'utf-8') as f_out:\n",
=======
    "    saving_order = ['From', 'Sent', 'To', 'CC', 'Bcc', 'Subject', 'Attachments', 'Importance', 'Body', 'isThread', 'isAutoreply', 'hasAllCapLine', 'hasBadDate']\n",
    "    bool_headers = ['isThread', 'isAutoreply', 'hasAllCapLine', 'hasBadDate']\n",
    "    \n",
    "    str_email_count = f\"%05d\" % sv_arg.email_count\n",
    "    filenm = str(str_email_count)+'_fn_'+sv_arg.infile.split('.')[0]+'_ln_'+str(sv_arg.line_no)+'.txt'\n",
    "    filenm_path = sv_arg.outputpath + '/' + filenm # will not work on Windows\n",
    "    with open(filenm_path, 'w+', encoding = 'utf-8') as f_out:\n",
    "    #with open(sv_arg.outputpath + '/'+str(sv_arg.email_count)+'-fn_'+sv_arg.infile.split('.')[0]+'-ln_'+str(sv_arg.line_no)+'.txt', 'w+', encoding = 'utf-8') as f_out:\n",
>>>>>>> a839cbc747bf2fabe6e949015d16e079f20bc262
    "        for key in saving_order:\n",
    "            if key in email:\n",
    "                if key == 'Body':\n",
    "                    f_out.write(key+': '+'\\n'.join(email[key]) + '\\n') # for body, join by space '\\n'\n",
    "                elif key in bool_headers:\n",
    "                    f_out.write(key+': '+ str(email[key]) +'\\n') # for bool type\n",
    "                else:\n",
    "                    f_out.write(key+': '+' '.join(email[key]) + '\\n')  # for others, join by ' '\n",
    "    sv_arg.email_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validEmail(email, sv_arg, save = True, saveAny = False):\n",
    "    valid = False\n",
    "    # email is valid if 2 or more sections are found\n",
    "    checking_section = ['From', 'To', 'Sent']\n",
    "    valid_count = 0\n",
    "    for section in checking_section:\n",
    "        if section in email:\n",
    "            valid_count+=1\n",
    "    if valid_count>=2:\n",
    "        valid = True\n",
    "    if saveAny or (save and valid):\n",
    "        saveEmail(email, sv_arg)\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeEmail(email, sv_arg, spt_arg):\n",
    "    # all lines in stack to body. even empty\n",
    "    email['Body'] = email['Body'] + spt_arg.stack\n",
    "    validEmail(email, sv_arg, save = True, saveAny = False)\n",
    "    \n",
    "    spt_arg.stack = [] \n",
    "    spt_arg.displacement_sections = []\n",
    "    spt_arg.prev_section = None  # GE: Correction. 2022-01-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isUselessLine(line, file_no = ''):\n",
    "    if line == '':\n",
    "        return True\n",
    "    if line == file_no:\n",
    "        return True\n",
    "    for regex, cleaning_reason in cleanReLib.items(): \n",
    "        if regex.match(line):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileNumber(infile):\n",
    "    spt = infile.split('-')\n",
    "    file_no = spt[0]\n",
    "    if len(spt)>1 and spt[1].isdigit():\n",
    "        file_no = file_no + '-' + spt[1]\n",
    "    return file_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SavingArgs:\n",
    "    inputpath: str # path to a folder ending with /\n",
    "    outputpath: str # path to a folder ending with /\n",
    "    infile: str = '' # filename only\n",
    "    email_count: int = 0\n",
    "    line_no: int = -1\n",
    "    \n",
    "@dataclass\n",
    "class SplittingArgs:\n",
    "    prev_section: str = None\n",
    "    stack: list = field(default_factory=list)\n",
    "    displacement_sections: list = field(default_factory=list)\n",
    "    capTolerance: int = 0\n",
    "#     appendingMode: bool = False   # Autoreply and attachment must be treated differently\n",
    "    isAutoMessage: bool = False\n",
    "    isAttachment: bool = False"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 68,
>>>>>>> a839cbc747bf2fabe6e949015d16e079f20bc262
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(sv_arg):\n",
    "    # define the bad date regex\n",
    "    re_wrong_date = re.compile(r'^Date:\\s?[0-9]{1,2}[/-][0-9]{1,2}[/-][0-9]{4}$')\n",
    "    \n",
    "    f_in = open(sv_arg.inputpath + sv_arg.infile, encoding=\"utf8\")\n",
    "    email = defaultdict(list)\n",
    "    file_no = getFileNumber(sv_arg.infile)\n",
    "    \n",
    "    # initialize SplittingArgs and email object\n",
    "    spt_arg = SplittingArgs()\n",
    "    email = defaultdict(list)\n",
    "    \n",
    "    for line_no, line in enumerate(f_in.readlines()):\n",
    "        sv_arg.line_no = line_no\n",
    "        # decrement capTolerance\n",
    "        spt_arg.capTolerance -= 1\n",
    "        \n",
    "        # if line start with >, it's in a thread    \n",
    "        line = line.strip(\"\\f\").strip()\n",
    "        if len(line) >0 and line[0] == '>':    \n",
    "            email['isThread'] = True\n",
    "        line = line.strip(\">\").strip()\n",
    "\n",
    "        # Skip some useless rows, including empty rows\n",
    "        if isUselessLine(line, file_no):\n",
    "            continue\n",
    "            \n",
    "        # correct typos\n",
    "        for typo, correction in typoLib.items(): \n",
    "            if typo in line:\n",
    "                line = line.replace(typo, correction)\n",
    "\n",
    "        # Autoreply and attachments are unlikely to have From: inside, but very likely to have To and Date.\n",
    "        # If found them, turn back to only consider From as the beginning of an email\n",
    "        # Only case to turn off appendingMode\n",
    "        if \"From:\" in line:\n",
    "            spt_arg.isAutoMessage = False\n",
    "            spt_arg.isAttachment = False\n",
    "        elif \"Subject:\" in line:\n",
    "            spt_arg.isAttachment = False\n",
    "            \n",
    "        \n",
    "        # append everything into body\n",
    "        if spt_arg.isAutoMessage or spt_arg.isAttachment:\n",
    "            spt_arg.stack.append(line)\n",
    "            continue\n",
    "            \n",
    "        # Autoreplys or autoforwards are found. First of three cases triggers appendingMode.\n",
    "        if \"Read:\" in line or \"Not read:\" in line or \"Sender:\" in line:\n",
    "            spt_arg.isAutoMessage = True\n",
    "            email['isAutoMessage'] = True\n",
    "\n",
    "        # For the case that From/Subject is wrongly appended to the end\n",
    "        # If people use \"From/Subject:\" in the content, this creates an incorrect split   \n",
    "        if \"From:\" in line:\n",
    "            spt = line.split(\"From:\")\n",
    "            if spt[0]:\n",
    "                spt_arg.stack.append(spt[0])\n",
    "                completeEmail(email, sv_arg, spt_arg)\n",
    "                email = defaultdict(list)\n",
    "                line = \"From:\" + spt[1]\n",
    "        elif \"Subject:\" in line:\n",
    "            spt = line.split(\"Subject:\")\n",
    "            if spt[0]:\n",
    "                spt_arg.stack.append(spt[0])\n",
    "                completeEmail(email, sv_arg, spt_arg)\n",
    "                email = defaultdict(list)\n",
    "                line = \"Subject:\" + spt[1]\n",
    "                \n",
    "        # Embedded attachments are found. Second of three cases triggers appendingMode.\n",
    "        # Attachments usually have a title line that all capital letters\n",
    "        # Add tolerance for all cap lines if comes right after a header section\n",
    "        elif spt_arg.capTolerance <= 0 and len(line) > 5 and all(word.isupper() for word in line.split()) and not '.' in line and not ':' in line:\n",
    "            spt_arg.isAttachment = True\n",
    "            spt_arg.stack.append(line)\n",
    "            email['hasAllCapLine'] = True\n",
    "            continue\n",
    "        \n",
    "        # if no pattern match, put into stack\n",
    "        line_to_stack = True\n",
    "\n",
    "        # search if line match any pattern\n",
    "        for regex, section in headerReLib.items():\n",
    "            if regex.match(line):\n",
    "                # if any header section is found, the next line can be all cap without trigger appendingMode\n",
    "                # capTolerance = 2 actually has 1 line tolerance. Because decrement is earlier than checking\n",
    "                spt_arg.capTolerance = 2 # can be larger, but with cautious\n",
    "                \n",
    "                # found a repeating header section, indicating current email ends\n",
    "                if section in email:  \n",
    "                    # Bad date found. Third of three cases triggers appendingMode.\n",
    "                    # This can be an attachment or an appointment\n",
    "                    if section == 'Sent' and re_wrong_date.match(line):\n",
    "                        spt_arg.stack.append(line)\n",
    "                        spt_arg.isAttachment = True\n",
    "                        email['hasBadDate'] = True\n",
    "                    else:\n",
    "                        completeEmail(email, sv_arg, spt_arg)\n",
    "                        email = defaultdict(list)\n",
    "                        \n",
    "                # section not in email, all lines in stack belongs to prev_section\n",
    "                elif spt_arg.stack:   \n",
    "                    if spt_arg.prev_section == None:\n",
    "                        print(\"If this is not happenning at the beginning of a file, is an error\")\n",
    "                        print('current line no:', line_no)\n",
    "                        spt_arg.stack = []\n",
    "                    else:\n",
    "                        email[spt_arg.prev_section] = email[spt_arg.prev_section] + spt_arg.stack\n",
    "                        spt_arg.stack = []\n",
    "                    if spt_arg.displacement_sections:\n",
    "                        spt_arg.displacement_sections.pop(0)\n",
    "                \n",
    "                # get rid of the header\n",
    "                line = regex.findall(line)[0]\n",
    "                email[section].append(line)\n",
    "                \n",
    "                # found empty, maybe it's a block displacement\n",
    "                if line == '': \n",
    "                    spt_arg.displacement_sections.append(section)\n",
    "                    spt_arg.capTolerance += 1 # if found empty header, there can have one more line all cap\n",
    "                spt_arg.prev_section = section\n",
    "                \n",
    "                # if match, don't append to stack.\n",
    "                # have to use flag here, because there are multiple patterns testing\n",
    "                line_to_stack = False\n",
    "                break\n",
    "\n",
    "        if line_to_stack:\n",
    "            spt_arg.stack.append(line)\n",
    "            \n",
    "        # if block displacement is found, and there are lines in the stack\n",
    "        if spt_arg.displacement_sections and spt_arg.stack:\n",
    "            popline = spt_arg.stack.pop(0)\n",
    "            section = spt_arg.displacement_sections.pop(0)\n",
    "            email[section].append(popline)\n",
    "            spt_arg.prev_section = section\n",
    "\n",
    "    # don't forget the last email\n",
    "    completeEmail(email, sv_arg, spt_arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "- Initialize SavingArgs with an inputpath and an outputpath as \n",
    "```python\n",
    "sv_arg = SavingArgs(inputpath = \"./test_input/\", outputpath = \"./test_output/\")\n",
    "```\n",
    "- For single file\n",
    "```python\n",
    "sv_arg.infile = \"9-1-Adam-Corey-2012-1-0.txt\"\n",
    "process(sv_arg)\n",
    "```\n",
    "- For multiple files\n",
    "```python\n",
    "for file in filenames:\n",
    "    sv_arg.infile = file\n",
    "    process(sv_arg)\n",
    "```\n",
    "\n",
    "**Note**\n",
    "If you want to rerun, it's better to reinitialize sv_arg, because sv_arg.email_count keeps increasing."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_arg = SavingArgs(inputpath = \"./test_input/all_txt/\", outputpath = \"./test_output/\")\n",
    "sv_arg.infile = \"34-5-ScottMaddox5.txt\"\n",
    "process(sv_arg)"
=======
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_ge = SavingArgs(inputpath= \"./email_txt/downloaded_from_data_tallahassee/\", outputpath = \"./test_output/\")\n",
    "sv_ge.email_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./email_txt/downloaded_from_data_tallahassee/ 23-11-PCSgmail2014-2017.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 15-6-HunterHarp2014-1.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 17-2-IB2013-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 34-1-ScottMaddox1-Redacted.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 1\n",
      "./email_txt/downloaded_from_data_tallahassee/ 18-5-Inkbridge2013-3-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 9-1-Adam-Corey-2012-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 12-CKittrell2012-2017.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 16-2-HunterHarpHoldings2012-2.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 31-2-GaryYordon2-Redacted-Files.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 3-1-AP-Payments-Combined.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 1089\n",
      "./email_txt/downloaded_from_data_tallahassee/ 18-10-Inkbridge2016-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 19-6-JohnBurnette2017.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 18-2-Inkbridge2012-2.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 21-7-KimRivers2014-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 14-3-Governance2013-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 18-1-Inkbridge2012-1.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 34-3-ScottMaddox3.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 14-2-Governance2012-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 32-3-PaigeCS-3-Redacted.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 18-6-Inkbridge2014-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 16-1-HunterHarpHoldings2012-1.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 15-8-HunterHarp2015-2017.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 23-7-PaigeCarter-Smith2017-3-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 21-2-KimRivers2013-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 32-2-PaigeCS-2.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 2\n",
      "./email_txt/downloaded_from_data_tallahassee/ 34-6-ScottMaddox6-Redacted.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 19-3-JohnBurnette2014.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 23-6-PaigeCarter-Smith2017-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 32-3-PaigeCS-3-2.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 2\n",
      "./email_txt/downloaded_from_data_tallahassee/ 9-8-Adam-Corey-2017.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 19-2-JohnBurnette2013.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 28-3-CoT-CAFR-FY-2014-CRA-Related.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 15-7-HunterHarp2014-2.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 28-5-CoT-CAFR-FY-2016-CRA-Related.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 31-1-GaryYordon-1-Redacted-Files.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 34-5-ScottMaddox5-Redacted.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 32-1-PaigeCS-2-Redacted.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 1\n",
      "./email_txt/downloaded_from_data_tallahassee/ 14-1-Governance2012-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 32-3-PaigeCS-3-1.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 2\n",
      "./email_txt/downloaded_from_data_tallahassee/ 23-8-PaigeCarter-Smith2017-4-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 18-12-Inkbridge2017.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 28-4-CoT-CAFR-FY-2015-CRA-Related.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 10-1-Cascade-2013.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 21-4-KimRivers2013-3-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 23-1-PaigeCarter-Smith2012-2015.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 10-5-Cascade-2015-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 9-3-Adam-Corey2014-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 34-2-ScottMaddox2.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 18-3-Inkbridge2013-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 18-8-Inkbridge2015-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 34-2-ScottMaddox2-Redacted.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 1\n",
      "./email_txt/downloaded_from_data_tallahassee/ 14-4-Governance2013-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 17-3-IB2013-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 21-9-KimRivers2015-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 14.2 -Governance2012-2.0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 17-1-IB2012-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 9-4-Adam-Corey-2014-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 10-4-Cascade-2015-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 17-8-IB2016-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 17-7-IB2015-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 23-2-PaigeCarter-Smith2016-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 10-6-Cascade-2016-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 32-1-PaigeCS-1-1.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 2\n",
      "./email_txt/downloaded_from_data_tallahassee/ 9-2-Adam-Corey2013-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ search_files.x\n",
      "./email_txt/downloaded_from_data_tallahassee/ 23-5-PaigeCarter-Smith2017-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 23-3-PaigeCarter-Smith2016-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 19-4-JohnBurnette2015.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 32-1-PaigeCS-1-2.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 2\n",
      "./email_txt/downloaded_from_data_tallahassee/ 32-1-PaigeCS-1-3.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 2\n",
      "./email_txt/downloaded_from_data_tallahassee/ 10-7-Cascade-2016-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 31-1-GaryYordon1.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 2\n",
      "./email_txt/downloaded_from_data_tallahassee/ 32-1-PaigeCS-1-Redacted.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 10-3-Cascade-2014-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 31-2-GaryYordon2-1.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 2\n",
      "./email_txt/downloaded_from_data_tallahassee/ 14-5-Governance2014-2017.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 34-1-ScottMaddox1.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 21-8-KimRivers2015-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 9-7-ACoreyAdam-Corey-2016-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 11-CBaker-2012-2017A.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 21-1-KimRivers2012.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 34-5-ScottMaddox5.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 13-FWhitley2012-2017.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 16-3-HunterHarpHoldings2013.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 18-9-Inkbridge2015-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 19-1-JohnBurnette2012.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 17-4-IB2014-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 31-2-GaryYordon2-2.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 2\n",
      "./email_txt/downloaded_from_data_tallahassee/ 31-2-GaryYordon2-3.txt\n",
      "If this is not happenning at the beginning of a file, is an error\n",
      "current line no: 2\n",
      "./email_txt/downloaded_from_data_tallahassee/ 9-5-Adam-Corey-2015-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 15-3-HunterHarp2013-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 21-5-KimRivers2013-4-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 11-CBaker-2012-2017B.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 15-2-HunterHarp2012-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 16-4-HunterHarpHoldings2014.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 10-2-Cascade-2014-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 15-1-HunterHarp2012-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 17-5-IB2014-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 28-2-CoT-CAFR-FY-2013-CRA-Related.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 17-10-IB2017.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 28-1-CoT-CAFR-FY-2012-CRA-Related.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 15-5-HunterHarp2013-3-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 18-4-Inkbridge2013-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 16-5-HunterHarpHoldings2015-2017.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 19-5-JohnBurnette2016.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 9-6-Adam-Corey-2015-2-0-D.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 9-6-Adam-Corey-2015-2-0-E.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 21-10-KimRivers2016.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 9-6-Adam-Corey2015-2-0-A.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 23-4-PaigeCarter-Smith2016-3-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 15-4-HunterHarp2013-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 23-10-PCSgmail2013-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 23-9-PCSgmail2012.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 21-3-KimRivers2013-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 10-8-Cascade-2017.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 18-7-Inkbridge2014-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 17-9-IB2016-2-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 17-6-IB2015-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 21-11-KimRivers2017.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 21-6-KimRivers2014-1-0.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 9-6-Adam-Corey-2015-2-0-B.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 9-6-Adam-Corey-2015-2-0-C.txt\n",
      "./email_txt/downloaded_from_data_tallahassee/ 18-11-Inkbridge2016-2-0.txt\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(sv_ge.inputpath)\n",
    "\n",
    "for inputfile in files: #notebook.tqdm(files[5]):\n",
    "    sv_ge.infile = inputfile\n",
    "    print(sv_ge.inputpath, inputfile)\n",
    "    process(sv_ge)"
>>>>>>> a839cbc747bf2fabe6e949015d16e079f20bc262
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non function code below"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "From:\n",
      "error!!!\n"
     ]
    }
   ],
   "source": [
    "re_wrong_date = re.compile(r'^Date:\\s?[0-9]{1,2}[/-][0-9]{1,2}[/-][0-9]{4}$')\n",
    "# all global variables\n",
    "inputpath = \"./test_input/all_txt/\"\n",
    "# inputpath = \"./read_original_text_files/email_txt/test_files/\"\n",
    "\n",
    "# infile = \"9-1-Adam-Corey-2012-1-0.txt\"\n",
    "infile = \"34-1-ScottMaddox1-Redacted.txt\"\n",
    "# infile = \"gordon2.txt\"\n",
    "\n",
    "spt = infile.split('-')\n",
    "file_no = spt[0]\n",
    "if len(spt)>1 and spt[1].isdigit():\n",
    "    file_no = file_no + '-' + spt[1]\n",
    "\n",
    "f_in = open(inputpath + infile, encoding=\"utf8\")\n",
    "outputpath = \"./test_output/\"\n",
    "# outputpath = \"./read_original_text_files/test_output/\"\n",
    "\n",
    "email_count = 0\n",
    "stack = []\n",
    "displacement_sections = []\n",
    "    \n",
    "# empty_line_count = 0\n",
    "# All sections are better to be lists. This is designed for the block displacement issue\n",
    "email = defaultdict(list)\n",
    "prev_section = None\n",
    "insideAttachment = False\n",
    "insideAutoreply = False\n",
    "capTolerance = 0\n",
    "# Iterate through the whole file\n",
    "for line_no, line in enumerate(f_in.readlines()):\n",
    "    capTolerance -= 1\n",
    "    \n",
    "    line = line.strip(\"\\f\").strip()\n",
    "    if line == '':\n",
    "        continue\n",
    "    if line[0] == '>':     # if line start with >, it's in a thread\n",
    "        email['isThread'] = True\n",
    "    line = line.strip(\">\").strip()\n",
    "\n",
    "    # Skip some useless rows, but not empty rows\n",
    "    if isUselessLine(line, file_no):\n",
    "#         print(\"This line seems useless\")\n",
    "#         print(line)\n",
    "        continue\n",
    "\n",
    "    # To identify autoreply\n",
    " \n",
    "    if \"From:\" in line:\n",
    "        insideAutoreply = False\n",
    "        insideAttachment = False\n",
    "        \n",
    "    if insideAutoreply or insideAttachment:\n",
    "        stack.append(line)\n",
    "        continue\n",
    "    if \"Read:\" in line or \"Not read:\" in line:\n",
    "        insideAutoreply = True\n",
    "        email['isAutoMessage'] = True\n",
    "    \n",
    "    # For the case that From/Subject is wrongly appended to the end\n",
    "    # If people use \"From/Subject:\" in the content, this creates an incorrect split   \n",
    "    if \"From:\" in line:\n",
    "        spt = line.split(\"From:\")\n",
    "        if spt[0]:\n",
    "            stack.append(spt[0])\n",
    "            completeEmail(email)\n",
    "            email = defaultdict(list)\n",
    "            line = \"From:\" + spt[1]\n",
    "    elif \"Subject:\" in line:\n",
    "        spt = line.split(\"Subject:\")\n",
    "        if spt[0]:\n",
    "            stack.append(spt[0])\n",
    "            completeEmail(email)\n",
    "            email = defaultdict(list)\n",
    "            line = \"Subject:\" + spt[1]\n",
    "    # Scanned documents are found. And usually contains To: that could mess up the splitting.\n",
    "    # Scanned documents usually have a title line that all capital letters\n",
    "    ### Only capture attachments if they have a capitalized line 5 or more characters\n",
    "    # Will not capture emails written ALL-CAP. (do we want that?)\n",
    "    elif capTolerance <= 0 and len(line) > 5 and all(word.isupper() for word in line.split()) and not '.' in line:\n",
    "        insideAttachment = True\n",
    "        email['hasEmbeddedAttachment'] = True\n",
    "        stack.append(line)\n",
    "        continue\n",
    "    #     if line =='':\n",
    "    #         empty_line_count += 1\n",
    "    #     else:\n",
    "    #         empty_line_count = 0\n",
    "    #     if empty_line_count >= 2:\n",
    "    #         email = defaultdict(list)\n",
    "    # if no pattern match, put into stack\n",
    "    line_to_stack = True\n",
    "    \n",
    "    # search if line match any pattern\n",
    "    for regex, section in headerReLib.items():\n",
    "        if regex.match(line):\n",
    "            # if any section is found, the next line can be all cap with trigger insideAttachment\n",
    "            # even if this is 2, still only 1 line tolerance. Because decrement is earlier than checking\n",
    "            capTolerance = 2 # can be larger, but with cautious\n",
    "            \n",
    "            insideAttachment = False\n",
    "            \n",
    "            if section in email:  # repeat headers, indicating current email ends\n",
    "                if section == 'Sent' and re_wrong_date.match(line):\n",
    "                    stack.append(line)\n",
    "                    insideAttachment = True\n",
    "                    email['hasEmbeddedAttachment'] = True\n",
    "                else:\n",
    "                    completeEmail(email)\n",
    "                    email = defaultdict(list)\n",
    "            elif stack:   # section not in email, but non-zero body\n",
    "                if prev_section == None:\n",
    "                    print(\"If this is not happenning at the beginning of a file, is an error\")\n",
    "                    stack = []\n",
    "                else:\n",
    "                    email[prev_section] = email[prev_section] + stack\n",
    "                    stack = []\n",
    "                if displacement_sections:\n",
    "                    displacement_sections.pop(0)\n",
    "            \n",
    "            line = regex.findall(line)[0]\n",
    "            \n",
    "            email[section].append(line)\n",
    "            if line == '': # found empty header\n",
    "                displacement_sections.append(section)\n",
    "                capTolerance += 1 # if empty add 1 \n",
    "            prev_section = section\n",
    "            # if match, don't append to stack.\n",
    "            # have to use flag here, because there are multiple patterns testing\n",
    "            line_to_stack = False\n",
    "            break\n",
    "            \n",
    "    if line_to_stack and not insideAttachment:\n",
    "        stack.append(line)\n",
    "    # if block displacement is found, and there are non-header lines in the stack\n",
    "    if displacement_sections and stack:\n",
    "        popline = stack.pop(0)\n",
    "        if not popline == \"\":  # might be an empty line between the block of headers and block of fillers\n",
    "            section = displacement_sections.pop(0)\n",
    "            prev_section = section\n",
    "            email[section].append(popline)\n",
    "    \n",
    "\n",
    "# don't forget the last email\n",
    "completeEmail(email)"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> a839cbc747bf2fabe6e949015d16e079f20bc262
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06202422-5196-48cc-b5ad-999baea2864c",
   "metadata": {},
   "source": [
    "# Read Sent Headers\n",
    "## 2022-01-19\n",
    "- Read all emails from a folder and identify all lines with the \"Sent:\" header. \n",
    "- Record the filename, and the line number within the filename, for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e42c357-9f96-477a-9aa2-bdc15759ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fcf3a20-88b7-4e05-9493-08331df2190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, re\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "import function_library3 as fctlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d1be4d-7266-422f-b22b-b484cc31a674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputpath=\"./email_txt/downloaded_from_data_tallahassee/\"\n",
    "inputpath=\"./test_output/\"\n",
    "# inputpath=\"./23-11/\"\n",
    "# inputpath=\"./34-3/\"\n",
    "# inputpath=\"./18-4/\"\n",
    "inputpath=\"./10-8/\"\n",
    "files = glob(inputpath + \"*.txt\")  # subset of files\n",
    "# files = [inputpath + \"test2.txt\"]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7970ee2d-6cc5-40f8-a2ac-68ed62349644",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4881afe67442dcb7720356de89ece8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:  1\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "files_dict = {}\n",
    "lines = []\n",
    "count = 0\n",
    "\n",
    "for file in tqdm(files):\n",
    "    with open(file, \"r\") as f:\n",
    "        local_lines = []\n",
    "        files_dict[file] = f.read().splitlines(); # \\n removed\n",
    "        append_line = False\n",
    "        # cmdline = \"grep -i isautomessage %s\" % file\n",
    "        # os.system(cmdline)\n",
    "        for line_no, line in enumerate(files_dict[file]):\n",
    "            if (re.search(\"Sent:\", line)): \n",
    "                full_line = f\"{line_no}, {file},  ===> , {line}\"\n",
    "                append_line = True\n",
    "                local_lines.append(full_line)\n",
    "                continue\n",
    "            if (re.match(\"isAutoMessage:\", line)):\n",
    "                append_line = False\n",
    "                count += 1\n",
    "                break\n",
    "            if (re.match(\"isDisplacement:\", line)):\n",
    "                append_line = False\n",
    "                count += 1\n",
    "                break\n",
    "\n",
    "        if append_line:\n",
    "            lines.extend(local_lines)\n",
    "            \n",
    "# All emails with isAutoMessage=True are ignored\n",
    "print(\"count: \", count)\n",
    "print(len(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aefa5a8-a92d-4c33-b35a-1adf1cdf9f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3, ./10-8/test2.txt,  ===> , Sent: Wednesday, May 18, 2016 10:35 AM\n",
      "477, ./10-8/test2.txt,  ===> , Sent:\n",
      "1, ./10-8/test3.txt,  ===> , Sent: Thursday, June 01, 2017 3:27 PM\n",
      "518, ./10-8/test3.txt,  ===> , Sent: Friday, May 20, 2016 10:28 AM\n",
      "557, ./10-8/test3.txt,  ===> , Sent: Friday, May 20, 2016 10:28 AM\n",
      "596, ./10-8/test3.txt,  ===> , Sent: Friday, May 20, 2016 10:28 AM\n",
      "703, ./10-8/test3.txt,  ===> , Sent: Wednesday, May 18, 2016 10:35 AM\n",
      "737, ./10-8/test3.txt,  ===> , Sent: Wednesday, May 18, 2016 10:35 AM\n",
      "771, ./10-8/test3.txt,  ===> , Sent: Wednesday, May 18, 2016 10:35 AM\n",
      "1245, ./10-8/test3.txt,  ===> , Sent:\n"
     ]
    }
   ],
   "source": [
    "for line in lines[0:10]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22709bef-ab28-44ac-9873-933cccc0ffd6",
   "metadata": {},
   "source": [
    "### Save Sent: Headers to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80d25731-3a8f-4e3c-b776-be4ffa1dbb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before, len(lines)  25\n"
     ]
    }
   ],
   "source": [
    "print(\"before, len(lines) \", len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3926f52a-d7b2-4b20-b7a6-d5c128500fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cea9f50e-feb2-4885-ba3e-42ff8ab5b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = fctlib.createDateFilters()\n",
    "subject_spelling = re.compile(r\"^.*(S\\s+?u\\s+?j\\s+?e\\s+?c\\s+?t\\s+?)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7a003ef8-4978-44f2-b915-83bc7bab097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_file_id(line):\n",
    "    return re.sub('[0-9]+-[0-9]+$', '', line) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fd93ce89-c84e-46bd-9b96-b4ac51220479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "### Only keep doubtful dates\n",
    "print(len(lines))\n",
    "# filters.append(re.compile('AM$'))\n",
    "kept = []\n",
    "for line in lines:\n",
    "    keep = True\n",
    "    line = remove_file_id(line)\n",
    "    line = subject_spelling.sub(\"Subject\", line)\n",
    "    for regex, value in filters.items():\n",
    "        if regex.match(line):\n",
    "            keep = False\n",
    "    if keep: \n",
    "        kept.append(line)\n",
    "print(len(kept))\n",
    "kept1 = kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6140beac-5160-472e-ba7e-44f4a52d2e2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# order kept array according to mail index\n",
    "ids = []\n",
    "id_search = re.compile(r\"^.*?([0-9]+)_fn.*$\")\n",
    "for row in kept:\n",
    "    # new_row = id_search.search(r\"\\1\", row)\n",
    "    # idd = re.sub(r\"([0-9]+?)_fn\", r\"\\1\", row)\n",
    "    # print(\"row: ...\", row)\n",
    "    match = re.match(r\"^.*?(\\d+)_fn.*$\", row)\n",
    "    # print(match)\n",
    "    if match:\n",
    "        idd = match.group(1)\n",
    "        ids.append(int(idd))\n",
    "        \n",
    "ids = np.array(ids)\n",
    "args = np.argsort(ids)\n",
    "print(len(ids))\n",
    "print(ids[args][0:20])\n",
    "kept1 = np.array(kept)[args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2e186b62-eeba-46bc-89de-f36a5109715d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"Sent_headers.txt\", kept1, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b2c41-5120-49be-8cdd-422538086ea7",
   "metadata": {},
   "source": [
    "## Sent Headers saved to file\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560b9d8-9c97-47a0-80e6-59357d898e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b5086-9b1a-4621-a8d8-59ce7217b5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a694c-90a2-4097-a649-97996a29dc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96635d-9832-4aec-87a4-c05e17174804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39410710-716f-4c4b-8105-30e7eab02869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9642d619-ae8e-4f9e-a3a1-a6c90d7ac62a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To: File Cascades Holdings, LLC dba The Edison Restaurant',\n",
       " 'From: Ruben Alfaras, Senior Vice President',\n",
       " 'Date: 5/ 1/2015',\n",
       " 'Subject: Assignment of Lease/Subordination Agreement',\n",
       " '',\n",
       " '470 Suwannee Street',\n",
       " 'Tallahassee, FL 32301',\n",
       " '',\n",
       " ' ',\n",
       " '',\n",
       " 'City of?l?allahassee is the landlord for the above referenced property. When Lender?s',\n",
       " 'counsel requested the Assignment of Lease/Subordination Agreement, City would not',\n",
       " 'agree to Sign unless we would accept the ?Except for? items noted on the collateral',\n",
       " 'description. Since the City is spending a great deal on this project and our funds will',\n",
       " 'mostly be used for equipment that can be removed, we have agreed to this request.',\n",
       " '',\n",
       " 'The Bank. feels this is a risk worth taking and would do the some were this a conventional',\n",
       " 'bank loan.',\n",
       " '',\n",
       " 'W,']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_dict[files[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fc32a19-c582-488a-8073-791b691f8265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for k in files_dict.keys(): print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f100b8e-a205-4f65-8129-1154ad1b46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in files_dict.keys():\n",
    "    # print(len(files_dict[k]))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19b8432e-cec5-43f5-9ca2-ed35e4fcdcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['date', 'sent', 'to', 'cc', 're', 'bcc', 'when', 'subject', 'original', 'from']\n",
    "folder = \"search_results\"\n",
    "# prefixes = ['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f64932ab-9100-4a30-b05c-8247dcf7e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "breakup_date = re.compile(r'([\\w-]+?.txt):(\\d+?):(.*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1065043a-d83b-4371-a704-382f151c10c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputpath:  search_results/date_txt\n",
      "inputpath:  search_results/sent_txt\n",
      "inputpath:  search_results/to_txt\n",
      "inputpath:  search_results/cc_txt\n",
      "inputpath:  search_results/re_txt\n",
      "inputpath:  search_results/bcc_txt\n",
      "inputpath:  search_results/when_txt\n",
      "inputpath:  search_results/subject_txt\n",
      "inputpath:  search_results/original_txt\n",
      "inputpath:  search_results/from_txt\n"
     ]
    }
   ],
   "source": [
    "dicts = {}\n",
    "for prefix in prefixes:\n",
    "    inputpath = os.path.join(folder, prefix + \"_txt\")\n",
    "    folder_list = []\n",
    "    dicts[prefix] = folder_list\n",
    "\n",
    "    with open(inputpath, \"r\", encoding=\"utf8\") as f:\n",
    "        print(\"inputpath: \", inputpath)\n",
    "        for line in f.readlines():\n",
    "            filenm, ln, rest = breakup_date.findall(line)[0]\n",
    "            # grep -n numbers lines from 1, and I want 0-based\n",
    "            d = {\"filenm\": filenm, \"ln\": int(ln)-1, \"rest\": rest.rstrip()}\n",
    "            folder_list.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "014e8f5e-09d5-457b-b00c-871a852f81c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date (15465, 3)\n",
      "sent (58640, 3)\n",
      "to (71105, 3)\n",
      "cc (36448, 3)\n",
      "re (33718, 3)\n",
      "bcc (172, 3)\n",
      "when (647, 3)\n",
      "subject (74181, 3)\n",
      "original (1, 3)\n",
      "from (71557, 3)\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "for k in dicts.keys():\n",
    "    dfs[k] = pd.DataFrame(dicts[k])\n",
    "    print(k, dfs[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad86c6f2-f1c4-4b78-ae39-9bce95bb4c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15465, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = dfs['date']\n",
    "dates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29f2e428-446d-4cd9-99ff-da996621e28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenm</th>\n",
       "      <th>ln</th>\n",
       "      <th>rest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>133</td>\n",
       "      <td>Date: Thursday, July 11, 2013 1:08 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>1381</td>\n",
       "      <td>Date: August 20, 2013, 6:24:26 PM EDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>1722</td>\n",
       "      <td>Date: Tue, Jun 25, 2013 at 11:45 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>2106</td>\n",
       "      <td>Date: Tue, Jun 25, 2013 at 11:45 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>2127</td>\n",
       "      <td>Date: Tue, Jun 25, 2013 at 11:45 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filenm    ln                                   rest\n",
       "0  10-1-Cascade-2013.txt   133  Date: Thursday, July 11, 2013 1:08 PM\n",
       "1  10-1-Cascade-2013.txt  1381  Date: August 20, 2013, 6:24:26 PM EDT\n",
       "2  10-1-Cascade-2013.txt  1722    Date: Tue, Jun 25, 2013 at 11:45 AM\n",
       "3  10-1-Cascade-2013.txt  2106    Date: Tue, Jun 25, 2013 at 11:45 AM\n",
       "4  10-1-Cascade-2013.txt  2127    Date: Tue, Jun 25, 2013 at 11:45 AM"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f14fb399-db61-4e44-9ea6-4069f544188a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15465"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = dates['rest'].values\n",
    "len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "631e7160-f15c-460b-bc1c-dd7653985ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15465"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest = dfs['date'].loc[:, 'rest'].values\n",
    "rest = [r.strip() for r in rest]\n",
    "rest = [r[5:].strip() if r[0:5].lower() == 'date:' else r.strip() for r in rest]\n",
    "for i, r in enumerate(rest):\n",
    "    rest[i] = re.sub(\"\\(GMT-05:00\\)\", \"\", r)\n",
    "dfs['date']['rest'] = rest\n",
    "len(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bfe2623b-181e-45c4-be1f-605c0cac3b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['date', 'sent', 'to', 'cc', 're', 'bcc', 'when', 'subject', 'original', 'from'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b164d-3d9e-4a05-9440-be0800eb02b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8dc6c28-f4da-451e-85c2-69245148b74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58640"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest = dfs['sent'].loc[:, 'rest'].values\n",
    "rest = [r.strip() for r in rest]\n",
    "rest = [r[5:].strip() if r[0:5].lower() == 'sent:' else r.strip() for r in rest]\n",
    "for i, r in enumerate(rest):\n",
    "    rr = re.sub(\"\\(GMT-05:00\\).*\", \"\", r)\n",
    "    rr = re.sub(\"\\(UTC-05:00\\).*\", \"\", rr)\n",
    "    rest[i] = rr\n",
    "dfs['sent']['rest'] = rest\n",
    "len(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3836b-ba5c-4b8b-bd5b-0cea4ab837c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "af394f35-71c0-4537-9b0d-4440dcd3187f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15465, 3), 58640)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['date'].shape, len(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1af9c99b-2ea3-40de-b55b-ddf471d3426c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenm</th>\n",
       "      <th>ln</th>\n",
       "      <th>rest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>133</td>\n",
       "      <td>Thursday, July 11, 2013 1:08 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>1381</td>\n",
       "      <td>August 20, 2013, 6:24:26 PM EDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>1722</td>\n",
       "      <td>Tue, Jun 25, 2013 at 11:45 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>2106</td>\n",
       "      <td>Tue, Jun 25, 2013 at 11:45 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>2127</td>\n",
       "      <td>Tue, Jun 25, 2013 at 11:45 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filenm    ln                             rest\n",
       "0  10-1-Cascade-2013.txt   133  Thursday, July 11, 2013 1:08 PM\n",
       "1  10-1-Cascade-2013.txt  1381  August 20, 2013, 6:24:26 PM EDT\n",
       "2  10-1-Cascade-2013.txt  1722    Tue, Jun 25, 2013 at 11:45 AM\n",
       "3  10-1-Cascade-2013.txt  2106    Tue, Jun 25, 2013 at 11:45 AM\n",
       "4  10-1-Cascade-2013.txt  2127    Tue, Jun 25, 2013 at 11:45 AM"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b0eb9-908f-4553-8b69-81cc87c3822c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27c83d8d-0f6a-4bb7-b5af-e92ba9c73554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenm</th>\n",
       "      <th>ln</th>\n",
       "      <th>rest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday, July 14, 2013 2:39 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>20</td>\n",
       "      <td>Sunday, July 14, 2013 2:39 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>39</td>\n",
       "      <td>Monday, July 15, 2013 8:18 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>192</td>\n",
       "      <td>Monday, July 15, 2013 8:35 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-1-Cascade-2013.txt</td>\n",
       "      <td>230</td>\n",
       "      <td>Monday, July 15, 2013 8:35 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filenm   ln                           rest\n",
       "0  10-1-Cascade-2013.txt    1  Sunday, July 14, 2013 2:39 PM\n",
       "1  10-1-Cascade-2013.txt   20  Sunday, July 14, 2013 2:39 PM\n",
       "2  10-1-Cascade-2013.txt   39  Monday, July 15, 2013 8:18 AM\n",
       "3  10-1-Cascade-2013.txt  192  Monday, July 15, 2013 8:35 AM\n",
       "4  10-1-Cascade-2013.txt  230  Monday, July 15, 2013 8:35 AM"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['sent'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e126f8b4-2bbf-4102-94d5-1bf0ae86cfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Thursday, July 11, 2013 1:08 PM\n",
      "1 August 20, 2013, 6:24:26 PM EDT\n",
      "2 Tue, Jun 25, 2013 at 11:45 AM\n",
      "3 Tue, Jun 25, 2013 at 11:45 AM\n",
      "4 Tue, Jun 25, 2013 at 11:45 AM\n",
      "5 November 19, 2013 at 7:51:38 PM EST\n",
      "6 November 19, 2013 at 7:51:38 PM EST\n",
      "7 November 26, 2013 at 11:06:32 AM EST\n",
      "8 November 26, 2013 at 11:06:32 AM EST\n",
      "9 November 26, 2013 at 11:06:32 AM EST\n",
      "10 December 10, 2013 at 4:32:37 PM EST\n",
      "11 Tue, Dec 10, 2013 2:06 PM\n",
      "12 December 10, 2013 at 4:32:37 PM EST\n",
      "13 Tue, Dec 10, 2013 2:06 PM\n",
      "14 December 10, 2013 at 4:32:37 PM EST\n",
      "15 Tue, Dec 10, 2013 2:06 PM\n",
      "16 December 10, 2013 at 4:32:37 PM EST\n",
      "17 Tue, Dec 10, 2013 2:06 PM\n",
      "18 December 10, 2013 at 4:32:37 PM EST\n",
      "19 Tue, Dec 10, 2013 2:06 PM\n",
      "20 December 10, 2013 at 4:32:37 PM EST\n",
      "21 Tue, Dec 10, 2013 2:06 PM\n",
      "22 December 10, 2013 at 4:32:37 PM EST\n",
      "23 Tue, Dec 10, 2013 2:06 PM\n",
      "24 December 10, 2013 at 4:32:37 PM EST\n",
      "25 Tue, Dec 10, 2013 2:06 PM\n",
      "26 December 10, 2013 at 4:32:37 PM EST\n",
      "27 Tue, Dec 10, 2013 2:06 PM\n",
      "28 December 10, 2013 at 4:32:37 PM EST\n",
      "29 Tue, Dec 10, 2013 2:06 PM\n",
      "30 December 5, 2013\n",
      "31 December 10, 2013 at 4:32:37 PM EST\n",
      "32 Tue, Dec 10, 2013 2:06 PM\n",
      "33 December 5, 2013\n",
      "34 December 10, 2013 at 4:32:37 PM EST\n",
      "35 Tue, Dec 10, 2013 2:06 PM\n",
      "36 December 5, 2013\n",
      "37 December 10, 2013 at 4:32:37 PM EST\n",
      "38 Tue, Dec 10, 2013 2:06 PM\n",
      "39 December 5, 2013\n",
      "40 December 13, 2013, 4:46:58 PM EST\n",
      "41 February 7, 2014 at 11:42:14 AM EST\n",
      "42 February 7, 2014 at 11:42:14 AM EST\n",
      "43 February 7, 2014 at 11:42:14 AM EST\n",
      "44 March 14, 2014 at 6:36:53 PM EDT\n",
      "45 March 14, 2014 at 6:36:53 PM EDT\n",
      "46 Tue, Mar 18, 2014 at 5:03 PM\n",
      "47 Tue, Mar 18, 2014 at 5:03 PM\n",
      "48 FEB 6 2014 45-5577241\n"
     ]
    }
   ],
   "source": [
    "for i in range(49):\n",
    "    print(i, dfs['date'].loc[i, 'rest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65b1a248-cc76-4357-81a6-1318d3df5db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erlebach/opt/anaconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname PDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/Users/erlebach/opt/anaconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname CST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/Users/erlebach/opt/anaconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname PMEDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/Users/erlebach/opt/anaconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname MDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/Users/erlebach/opt/anaconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname CDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/Users/erlebach/opt/anaconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname HST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/Users/erlebach/opt/anaconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname PST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "dates1 = pd.to_datetime(dfs['date'].loc[:, 'rest'], errors='coerce');\n",
    "# lines of data_indexes translated to NaT, so are not valid date-times\n",
    "NaT_date_indexes = dates1[dates1.isna() == True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6987f90-0a57-4b6d-b4ad-07e24d83e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d037d20-696f-4f04-b815-11338d98144c",
   "metadata": {},
   "source": [
    "d = dates.iloc[NaT_date_indexes,:]\n",
    "for i in range(1000):\n",
    "    print(d.iloc[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eafe2c5-bffe-4fa8-90a4-c0f5a307b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = pd.to_datetime(dfs['sent'].loc[:, 'rest'], exact=False, errors='coerce');\n",
    "# lines of data_indexes translated to NaT, so are not valid date-times\n",
    "NaT_sent_indexes = dates1[sent1.isna() == True].index\n",
    "sent_NaT = dfs['sent'].iloc[NaT_sent_indexes]\n",
    "NaT_sent_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd41060f-af25-4785-98ca-bb987cd9b169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Most errors start with >Sent, which are not original emails, but rather, Re, Fwd, or emails inside threads. \n",
    "# So we can remove them. On the other side, \n",
    "# sent_NaT.head(50)\n",
    "count = 0\n",
    "inputpath=\"./email_txt/downloaded_from_data_tallahassee/\"\n",
    "\n",
    "rows = []\n",
    "for row in sent_NaT.iterrows():\n",
    "    # Only print the lines that do not start with >\n",
    "    # if sent_NaT.loc[i, 'rest'].value != '>':a\n",
    "    ln = int(row[1][1])\n",
    "    fn = row[1][0]\n",
    "    rest = row[1][2]\n",
    "    # print(\"fn: \", fn)\n",
    "    # print(\"inputpath: \", inputpath)\n",
    "    # print(\"files_dict.keys(): \", files_dict.keys())\n",
    "    # lines = files_dict[inputpath+fn]\n",
    "    # print(\"lines: \", lines[ln : ln+1], \"\\n\")\n",
    "    # print(\"ln: \", ln)\n",
    "    if row[1][2][0] != '>':\n",
    "        lines = files_dict[inputpath+fn]\n",
    "        # Took care of zero-based line numbers earlier in this file\n",
    "        # print(\"lines: \", lines[ln : ln+2])\n",
    "        # print(fn, ln, rest)\n",
    "        # print()\n",
    "        Lines = \" \".join(lines[ln:ln+10])\n",
    "        # Remove \"Sent:\" if it occurs at the front\n",
    "        Lines = re.sub(\"\\b.*?Sent:\", \"\", Lines)\n",
    "        # Remove leading \">\" denoting threads\n",
    "        Lines = re.sub(\">+? Sent:\", \"\", Lines)\n",
    "        # Remove from To: onward \n",
    "        Lines = re.sub(\"(.*?)(To:.*)\", r\"\\1\", Lines)\n",
    "        Lines = re.sub(\"\\*\\*\", \"\", Lines)\n",
    "        # Fix \"...Tuesday August 26:\" into \"...Tuesdsay August 26, \"...\n",
    "        Lines = re.sub(\"([a-z] [0-9]*?):\", r\"\\1, \", Lines)\n",
    "        # Replace \": \" by \":\" to handle bad time\n",
    "        Lines = re.sub(\": \", \":\", Lines)\n",
    "\n",
    "        # print(\"row: \", row)\n",
    "        rows.append(Lines)\n",
    "        # print(\"Lines: \", Lines)\n",
    "        count += 1\n",
    "        #print(\"-------------------------\")\n",
    "    #( print(sent_NaT.loc[i, 'rest'])\n",
    "print(\"count= \", count)\n",
    "ddf = pd.DataFrame({'col':rows})\n",
    "datess = pd.to_datetime(ddf['col'], exact=False, errors='coerce')\n",
    "print(datess)\n",
    "print(ddf)\n",
    "\"\"\"\n",
    "31   Thursday, April 09, 2015 06:04 AM US Mountain...\n",
    "32   Thursday, April 09, 2015 06:04 AM US Mountain...\n",
    "Perhaps add a column of time corrections? mostly 0, but +2 hours if US Mountain ...? \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e52b3-22ef-40d6-bce0-06453c947774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8406877-aad5-439a-8e47-b768bc5259c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980a9114-bad6-4fa0-8172-a70c53aa0532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "218478229a7048a9b46ff57c9675eb9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4e70479c32854d84818cea9cca67d09e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5f4881afe67442dcb7720356de89ece8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_771530778c0e4b82838bb1c7e53adb8e",
        "IPY_MODEL_7b17e576b21a414ca94454d323cca6b8",
        "IPY_MODEL_c16dd061d43c4bb29ec03f54c28b3613"
       ],
       "layout": "IPY_MODEL_b44afc65d27240d1866fae9265574cf5"
      }
     },
     "6410e15bdc354d5483642e5a5142cbad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "771530778c0e4b82838bb1c7e53adb8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e3c312cd48c54c91979800d42d9a52dd",
       "style": "IPY_MODEL_6410e15bdc354d5483642e5a5142cbad",
       "value": "100%"
      }
     },
     "7b17e576b21a414ca94454d323cca6b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_8063439545184db99b69ad4105091348",
       "max": 9,
       "style": "IPY_MODEL_4e70479c32854d84818cea9cca67d09e",
       "value": 9
      }
     },
     "8063439545184db99b69ad4105091348": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ae9bea93eeb04e2bb5f32fa4951cac84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b44afc65d27240d1866fae9265574cf5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c16dd061d43c4bb29ec03f54c28b3613": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ae9bea93eeb04e2bb5f32fa4951cac84",
       "style": "IPY_MODEL_218478229a7048a9b46ff57c9675eb9c",
       "value": " 9/9 [00:00&lt;00:00, 316.17it/s]"
      }
     },
     "e3c312cd48c54c91979800d42d9a52dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# CRA network code

## Preprocessing (Updated Feb 11, 2022)

Step 1: Splitting emails

By this time, you should have all text files from https://data.tallahassee.com/fbi-cra-documents/ ready in a folder.

"preprocessing_testing.ipynb" will identify individual emails from a collection of multiple email text, save them as individual files to another folder.

Step 2: Splitting emails

"building csv.ipynb" reads each individual files generated by the previous step, identify headers, and build a csv.

## Input data information

Using 'output4.csv' as the inputing data, in which emails are sorted in time ascending order.

## File desciption

### function_library.py

'function_library.py' contains all the functions that are used.

### new_preprocess.py

'new_preprocess.py' is the file that process 'output4.csv'. The first pass drops several useless columns from the original dataframe for efficiency. The second pass will standardize names to be triplets in the form of (first_name, last_name, email_address). For some special cases, where at least one of the triplet is missing, a fake name or fake email address will be assigned.

TODO:
1. add a column to the dataframe to show whether the email is sent in day time or night time
2. calculate some stats about the length of title and subject, and add to the dataframe as columns
3. generate a sender/recipient by year table, sort the table by the total number of emails in the row.

### network_graph.py

'network_graph.py' reads the pickle file generated by 'new_preprocess.py', create connection matrix, create id2name dictionary using the sorted unique name list. In the end, the plot is generated and saved into pdf.

### Some old/testing codes

Old codes include: networkx.ipynb, networkx_ge.py, preprocess.py

Testing codes include: string_tests.py

All can be cleaned later.

#-------------------------------------------------------------

Column descriptions of the file output_with_stats_columns.csv . 
Each row corresponds to an email. Duplicates have been removed. 
Two mails are duplicates of each other if the following fields match: 
'From', 'To', 'Sent', 'Body' . This is probably not foolproof. 
We started with 71,143 emails, and have 39,444 emails after removal of 
duplicates. Note that these emails were printed to pdf by the FBI, and 
we then translated the pdf to ascii. There are quite a few errors, with many 
fields missing. However, we did not access to the original emails. 

A collection of pdfs were translated to text files (some available at Tallahassee
Democrat). A text file might have a name such as: "18-3-Inkbridge2013-1-0.txt" . 
These files are broken up into  individual emails, with all headers written in a standard
order (which is not the case in emails), and with several additional headers to characterize
the email more precisely. We generated 71,143 emails. Each email is stored in a separate
file. A typical file name might be: "23793_fn_18-3-Inkbridge2013-1-0_ln_130.txt". The first 
five digits constitute the email id, ranging from  0 to 71,142. Next is the name of the 
pdf file that contains the email, prefixed by "fn", and finally, the line number that 
corresponds to the last line of the email, prefixed by "ln". 

filenm: string
	The filename that contains the email at this row. 

From: string that encloses a tuple of three strings
	The mail originator (i.e., sender). It is always a single person. Sometimes there is more information than 
	the sender, which indicates some error in the conversion from text to mail. The process is 
	imperfect. 

Sent: string
    The time at which the email was sent. This must be converted to a proper datetime object, such as 
	the number of seconds from a specific point in time. Note that all times should have the same frame
	of reference. In this field, one finds times in multiple time zones, such as EST, GST, PST, etc. 
	The time registrationn is a task that remains to be done. 

To: string

CC: 

Bcc: 

Subject: 

Attachments: 

Importance: 

isThread: 

isAutoMessage: 

isDisplacement: 

hasAllCapLine: 

hasBadDate: 

Body: 

nb_words:

nb_chars: 

body_len: 

body: 

Error_from: 

Error_sent: 

mn_nb_words: 

std_nb_words: 

mn_nb_chars: 

std_nb_chars: 

#-------------------------------------------------------------
